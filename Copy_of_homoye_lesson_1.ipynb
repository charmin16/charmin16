{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of homoye_lesson_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNU6wjDjWbaWI2KC0e4dlG+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charmin16/charmin16/blob/main/Copy_of_homoye_lesson_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vZ9TlsgKOox"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xCwYV--GBQL",
        "outputId": "a5a6af88-d167-4684-b47c-4c608233bd71"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "arr = [6,7,8,9]\n",
        "print(type(arr))\n",
        "\n",
        "a = np.array(arr)\n",
        "print(type(a))\n",
        "\n",
        "print(a.shape)\n",
        "\n",
        "print(a.dtype)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'numpy.ndarray'>\n",
            "(4,)\n",
            "int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6kHJmIRKViD"
      },
      "source": [
        "Get the dimension of 'a' on the cell above by using ndim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9q3OMrfzLDcr",
        "outputId": "05cd8137-5b37-4c5b-bbd2-5b2931e272c2"
      },
      "source": [
        "print(a.ndim)\n",
        "b = np.array([[1,2,3,21], [5,6,7,18], [8, 9, 1, 12]])\n",
        "print(b)\n",
        "print(b.shape)\n",
        "print(b.ndim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "[[ 1  2  3 21]\n",
            " [ 5  6  7 18]\n",
            " [ 8  9  1 12]]\n",
            "(3, 4)\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQnTIT4v6283",
        "outputId": "725df436-be05-4207-fc9c-ad1eb7c15791"
      },
      "source": [
        "import numpy as np\n",
        "arr = [3,4,5,6,7]\n",
        "arn = np.array(arr)\n",
        "# print(type(arr))\n",
        "# print(type(arn))\n",
        "# print(arn.shape)\n",
        "# print(arn.dtype)\n",
        "\n",
        "# a = np.array([[9,2,3,4,5], [12,4,5,6,9], [ 22,8,9,4,1]])\n",
        "# print(a)\n",
        "# print(type(a))\n",
        "# print(a.shape)\n",
        "# print(a.ndim)\n",
        "# print(a.dtype)\n",
        "# print(arn.shape)\n",
        "# print(arn.ndim)\n",
        "\n",
        "# a 2x3 array with random values\n",
        "# np.random.random((2,3))\n",
        "\n",
        "# a 2x3 array of zeros\n",
        "# np.zeros((2,3))\n",
        "\n",
        "# a 2x3 array of ones\n",
        "# np.ones((2,3))\n",
        "\n",
        "# a 3x3 identity matix\n",
        "# np.identity(3)\n",
        "\n",
        "a = [4,8,9,12]\n",
        "az = np.array(a)\n",
        "\n",
        "b = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "c = np.array([[9.0, 8.0, 7.0], [1.0, 2.0, 3.0]])\n",
        "\n",
        "d = np.array([[4.0, 5.0, 6.0], [9.0, 8.0, 7.0]])\n",
        "\n",
        "e = c + d\n",
        "\n",
        "print(b[1,1]) # What this means: the first 1 in the bracket represents the second second dimension: [4,5,6], the seond 1 represents the index(second in this second dimension). So b[1,1] = 5\n",
        "f = np.array([[10, 11, 12], [13, 14, 15], [16, 17, 18], [19, 20, 21]])\n",
        "# print(f[:3, :2]) # :3 means we are considering 0,1,2 dimensions which is the first three arrays. We will now perform :2 on these first three arrays of interest, therefor the 0 and 1 index in the first three arrays will suffice\n",
        "# print(f[:2, :2])\n",
        "\n",
        "# Other advanced methods of indexing are shown below\n",
        "# print(f[[2, 0, 3, 1], [2, 1, 0, 2]]) # from the 2nd dimension(third  array) pick the second index(3rd element). From the 0th dimension(first array), pick the first index(second element), just like that till you get to the end\n",
        "\n",
        "print(f[f>15]). # boolean indexing meeting a specified condition\n",
        "\n",
        "# ls = [1,2,3,4,5,6]\n",
        "# print(ls[0:3])\n",
        "\n",
        "# print(az[0])\n",
        "# print(b[0,0])\n",
        "# print(b[1,2])\n",
        "# print(c[0,1])\n",
        "\n",
        "\n",
        "# print(e)\n",
        "# print(c.dtype)\n",
        "# print(c + d)\n",
        "# print(c * d)\n",
        "# print(5/d)\n",
        "# print(c ** 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "[16 17 18 19 20 21]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrLC6fDx0Fbh",
        "outputId": "0bf74cd9-5f72-4bc5-d922-e3fedbaf1025"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "days = pd.Series(['Monday', 'Tuesday', 'Wednesday'])\n",
        "# print(days)\n",
        "\n",
        "# creating series with a numpy array\n",
        "\n",
        "days_list = np.array(['Monday', 'Tuesday', 'Wednesday'])\n",
        "numpy_days = pd.Series(days_list)\n",
        "#print(numpy_days)\n",
        "\n",
        "# Using strings as index\n",
        "\n",
        "days = pd.Series(['Monday', 'Tuesday', 'Wednesday'],\n",
        "index = ['a', 'b', 'c'])\n",
        "\n",
        "# Create series from a dictionary\n",
        "\n",
        "days1 = pd.Series({'a': 'Monday', 'b': 'Tuesday', 'c': 'Wednesday'})\n",
        "print(days)\n",
        "print(days1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a       Monday\n",
            "b      Tuesday\n",
            "c    Wednesday\n",
            "dtype: object\n",
            "a       Monday\n",
            "b      Tuesday\n",
            "c    Wednesday\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-6C8I4ePv8Q",
        "outputId": "1dc4c3dd-42d8-499a-f167-296752b06f1a"
      },
      "source": [
        "import numpy as np\n",
        "# a = np.array([1,2,3,4,5,6])\n",
        "# print(type(a))\n",
        "# print(a.dtype)\n",
        "# print(a.shape)\n",
        "# print(a.ndim)\n",
        "\n",
        "b = np.array([[1,2,3,4], [6,7,8,11], [1,7,9,10], [1,3,5,14]])\n",
        "# print(type(b))\n",
        "# print(b.shape)\n",
        "# print(b.dtype)\n",
        "# print(b.ndim)\n",
        "\n",
        "# print(b[0,2])\n",
        "# print(b[1,0])\n",
        "# print(b[2,2])\n",
        "\n",
        "# print(b[:3, :3])\n",
        "# print(b[0, :3])\n",
        "# print(b[1, :-1])\n",
        "\n",
        "c = np.array(['manager', 'orange', 'guava'])\n",
        "# print(type(c))\n",
        "# print(c.dtype)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<U7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmY_daH4k71T",
        "outputId": "71e2b258-dcc0-4d6a-bdb0-2ab92981d87a"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "days = pd.Series(['Monday', 'Tuesday', 'Wednesday'])\n",
        "# print(days)\n",
        "\n",
        "# Creating series with a numpy array\n",
        "days_list = np.array(['Monday', 'Tuesday', 'Wednesday'])\n",
        "numpy_days = pd.Series(days_list)\n",
        "# print(numpy_days)\n",
        "\n",
        "# Using strings as index\n",
        "\n",
        "dayi = pd.Series(['Monday', 'Tuesday', 'Wednesday'], \n",
        "                 index = ['a', 'b', 'c'])\n",
        "#print(dayi)\n",
        "\n",
        "# Create series from a dictionary\n",
        "\n",
        "dayd = pd.Series({'a': 'Monday', 'b': 'Tuesday', 'c': 'Wednesday',\n",
        "                  'e': 'Thursday'})\n",
        "# print(dayd)\n",
        "\n",
        "# Series can be accessed using the specified index as shown below\n",
        "\n",
        "# print(days[0])\n",
        "# print(days[1:])\n",
        "# print(dayi[1:])\n",
        "# print(dayd[0:3:2]). # from index 0(first element) to index 3 at an interval of 2\n",
        "# print(dayd[::-1]) # Reverses the order/arrangement\n",
        "# print(dayi['c'])\n",
        "# z = [1,2,3,4,5,6]\n",
        "# print(z[::-1])\n",
        "\n",
        "# A DataFrame can be be described as a table (2 dimensions) made up of many series with the same index\n",
        "# It holds data in rows and columns just like a spreadsheet. Series, dictionaries, lists and other dataframes\n",
        "# and numpy arrays can be used to create new ones\n",
        "\n",
        "# print(pd.DataFrame())\n",
        "\n",
        "# Create a dataframe from a dictionary\n",
        "\n",
        "df_dict = {'Country': ['Ghana', 'Kenya', 'Nigeria', 'Togo'],\n",
        "           'Capital': ['Accra', 'Nairobi', 'Abuja', 'Lome'],\n",
        "           'Population': [10000, 8500, 35000, 12000],\n",
        "           'Age': [60, 70, 80, 75] }\n",
        "dfd = pd.DataFrame(df_dict, index = [2,4,6,8])\n",
        "# print(dfd)\n",
        "\n",
        "df_list = [['Ghana', 'Accra', 10000, 60],\n",
        "           ['Kenya', 'Nairobi', 8500, 70],\n",
        "           ['Nigeria', 'Abuja', 35000, 80],\n",
        "           ['Togo', 'Lome', 12000, 75]]\n",
        "dfl = pd.DataFrame(df_list, columns = ['Country', 'Capital', 'Population', 'Age'],\n",
        "                   index = [1,2,3,4])\n",
        "# print(dfl)\n",
        "\n",
        "# at, iat, iloc and loc are accessors used to retrieve data in dataframes. iloc selects\n",
        "# from the rows and columns by using integer index to locate positions while loc selects\n",
        "# rows and columns using labels. at and iat are used to retrieve single values such that at\n",
        "# uses the column and row labels and iat uses indices.\n",
        "\n",
        "# select the row in the at index 3\n",
        "# print(dfd.iloc[0]) # index 0 would be the first item(row) on the table\n",
        "\n",
        "# select row with index number\n",
        "# print(dfd.loc[4])\n",
        "# print(dfd.loc[8])\n",
        "\n",
        "# select the capital column\n",
        "# print(dfd['Capital'])\n",
        "\n",
        "# Using at and iat\n",
        "\n",
        "# print(dfd.at[6, 'Country'])\n",
        "# print(dfd.at[8, 'Capital'])\n",
        "# print(dfd.iat[0,1])\n",
        "# print(dfd.iat[1,2])\n",
        "\n",
        "'''Indexing in pandas are immutable arrays with unique elements or can be \n",
        "described as ordered sets for retrieving data in a dataframe and collaborating\n",
        "with multiple dataframes.\n",
        "\n",
        "The important Pandas functionalities: indexing, reindexing, selection, group,\n",
        "drop entities, ranking, sorting, duplicates and indexing by hierachy.'''\n",
        "\n",
        "# print(dfd['Population'].sum())\n",
        "# print(dfd['Age'].sum())\n",
        "# print(dfd.mean())\n",
        "# print(dfd.describe())\n",
        "\n",
        "# THE MISSING DATA ENIGMA\n",
        "'''Often data used for analysis in real life scenarios is imcomplete as a result of\n",
        "omission, faulty devices and mnay other factors. Pandas represent missing values as\n",
        "NA or NaN which  can be filled, removed and detected with functions like fillna(),\n",
        "dropna(), isnull(), replace()'''\n",
        "\n",
        "new_dic2 = {'Name': ['James', 'Yemen', 'Caro', np.nan],\n",
        "          'Porfession': ['Researcher', 'Artist', 'Doctor', 'Writer'],\n",
        "          'Height': [np.nan, 175,180, 150],\n",
        "          'Experience': [12, np.nan, 10, 8]}\n",
        "new_df = pd.DataFrame(new_dic2)\n",
        "# print(new_df)\n",
        "\n",
        "# Check for cells with missing values as True\n",
        "# #print(new_df.isnull())\n",
        "\n",
        "# remove rows with  missing  values\n",
        "print(new_df.dropna())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Name Porfession  Height  Experience\n",
            "2  Caro     Doctor   180.0        10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "EHMrn5j-7j06",
        "outputId": "17945766-fe64-44f9-fb12-9973de4fcdb4"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "days_week = pd.Series(['Monday', 'Tuesday', 'Wedesday', 'Thursday'],\n",
        "index = [1, 2, 3, 4])\n",
        "days = pd.Series(days_week)\n",
        "# print(type(days))\n",
        "# print(days_week)\n",
        "\n",
        "dayz = pd.Series(['Mon', 'Tues', 'Wed', 'Thurs', 'Fri'], \n",
        "                 index = ['a', 'b', 'c', 'd', 'e'])\n",
        "# print(dayz)\n",
        "# print(dayz['b':])\n",
        "# print(dayz[2])\n",
        "\n",
        "df = {'Country': ['Nigeria', 'Ghana', 'Kenya', 'Togo'],\n",
        "       'Capital': ['Abuja', 'Accra', 'Nairobi', 'Lome'],\n",
        "       'Population': [100000, 80000, 60000, 40000],\n",
        "       'Age': [88, 74, 79, 67]}\n",
        "dfd1 = pd.DataFrame(df)\n",
        "dfd = pd.DataFrame(df, index = ['a', 'b', 'c', 'd'])\n",
        "#print(dfd1)\n",
        "# print(dfd)\n",
        "\n",
        "df = [['Nigeria', 'Abuja', 100000, 88], ['Ghana', 'Accra', 80000, 74],\n",
        "      ['Kenya', 'Nairobi', 60000, 79], ['Togo', 'Lome', 40000, 67]]\n",
        "dfl = pd.DataFrame(df, columns = ['Country', 'Capital', 'Population', 'Age'])\n",
        "dfli = pd.DataFrame(df, columns = ['Country', 'Capital', 'Population', 'Age'],\n",
        "                   index = ['a', 'b', 'c', 'd'])\n",
        "# print(dfli)\n",
        "\n",
        "# '''at iat, iloc, loc are accessors used to retrieve data in dataframes.\n",
        "# iloc selects values from the rows and columns by using integer index to\n",
        "# locate positions while loc selects rows or columns using labels. This is\n",
        "# demonstrated below'''\n",
        "\n",
        "# select the row in the at index 2\n",
        "# print(dfl.iloc[2:])\n",
        "\n",
        "# select the row with index label 'b' in dfd\n",
        "# print(dfd.loc['a'])\n",
        "# print(dfli.loc['b':])\n",
        "# print(dfd['Capital'])\n",
        "\n",
        "# at and iat are used to retrieve single values such that at\n",
        "# uses the column and row labels and iat uses indices\n",
        "\n",
        "# print(dfd.iat[3,3])\n",
        "# print(dfli.iat[1,2])\n",
        "# print(dfli.at['d', 'Capital'])\n",
        "# print(dfli.at['c', 'Age'])\n",
        "\n",
        "# print(dfd['Population'].sum())\n",
        "# print(dfd.mean())\n",
        "# print(dfd.describe())\n",
        "    \n",
        "# DATA TYPES AND DATA WRANGLING\n",
        "\n",
        "csv_df = pd.read_csv('sample_file.csv')\n",
        "csv_df.to_csv('sample_file.csv', index = False)\n",
        "# print(csv_df)\n",
        "\n",
        "# sometimes dependent on the xlrd library which can be installed by running\n",
        "# pip install xlrd in the terminal\n",
        "\n",
        "excel_df = pd.read_excel('sample_file.xlsx')\n",
        "excel_df.to_excel('sample_file.xlsx')\n",
        "\n",
        "# read table from a webpage and save as a dataframe\n",
        "\n",
        "html_df = pd.read_html('http://www.webpage.com/sampledata.html')\n",
        "html_df.to_html('sample_file.html')\n",
        "\n",
        "# Pandas can connect to databases, get data with queries and save in a dataframe\n",
        "\n",
        "url = 'https://github.com/WalePhenomenon/climate_change/blob/master/fuel_ferc1.csv?raw = true'\n",
        "fuel_data = pd.read_csv(ur1,error_bad_lines = False)\n",
        "fuel_data.describe(include = 'all')\n",
        "print(fuel_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6ee67eca4b59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# DATA TYPES AND DATA WRANGLING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mcsv_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_file.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0mcsv_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_file.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# print(csv_df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample_file.csv'"
          ]
        }
      ]
    }
  ]
}